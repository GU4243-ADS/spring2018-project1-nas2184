wordcloud(hpl.words, hpl.freqs, scale = c(5, .2), min.freq = 3, max.words = Inf, random.order = FALSE, rot.per = .15, colors = pal)
dev.off()
# Subset data to EAP only and make bigrams
eap.bigrams <- spooky %>%
filter(author == "EAP") %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
eap.bigrams %>%
count(bigram, sort = TRUE)
# Split bigram into one word per column
eap.split <- eap.bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
# Filter bigrams by "not"
eap.filtered <- eap.split %>%
filter(word1 == "not")
# Remove stop_words except for not
eap.filtered$word <- eap.filtered$word2
eap <- anti_join(eap.filtered, stop_not, by = "word")
# eap.words is a list of words, and eap.freqs their frequencies
eap.words <- count(group_by(eap, word2))$word2
eap.freqs <- count(group_by(eap, word2))$n
png("../figs/Wordcloud_eap_not.png")
wordcloud(eap.words, eap.freqs, scale = c(5, .2), max.words = Inf, random.order = FALSE, rot.per = .15, colors = pal)
dev.off
stop_no <- stop_words %>%
filter(word %in% c("neither", "never", "no", "nobody", "non", "none", "noone", "not", "nothing", "nowhere"))
stop_neg <- anti_join(stop_words, stop_no, by = "word")
spooky_neg <- spooky %>%
unnest_tokens(word, text) %>%
anti_join(stop_neg, by = "word")
author_neg <- count(group_by(spooky_neg, word, author))
all_words_neg <- rename(count(group_by(spooky_neg, word)), all = n)
author_neg <- left_join(author_neg, all_words_neg, by = "word")
author_neg <- arrange(author_neg, desc(all))
author_neg <- ungroup(head(author_neg, 100))
png("../figs/author_neg.png")
ggplot(author_neg) +
geom_col(aes(reorder(word, all, FUN = min), n, fill = author)) +
scale_fill_manual( values = c("lightsteelblue3","lemonchiffon2","honeydew4")) +
xlab(NULL) +
coord_flip() +
facet_wrap(~ author) +
theme(legend.position = "none")
dev.off()
createFE <- function(ds)
{
ds = ds %>%
mutate(Ncommas = str_count(ds$text, ",")) %>%
mutate(Nsemicolons = str_count(ds$text, ";")) %>%
mutate(Ncolons = str_count(ds$text, ":"))
return(ds)
}
spooky <- createFE(spooky)
png("../figs/commas.png")
spooky %>%
group_by(author) %>%
summarise(SumCommas = sum(Ncommas,na.rm = TRUE)) %>%
ungroup() %>%
mutate(author = reorder(author,SumCommas)) %>%
ggplot(aes(x = author,y = SumCommas)) +
geom_bar(stat='identity',colour="white", fill = "slategray2") +
labs(x = 'Author',
y = 'Commas',
title = 'Author and Total Number of Commas') +
coord_flip() +
theme_bw()
dev.off()
png("../figs/semicolons.png")
spooky %>%
group_by(author) %>%
summarise(SumSemiColons = sum(Nsemicolumns,na.rm = TRUE)) %>%
ungroup() %>%
mutate(author = reorder(author,SumSemiColons)) %>%
ggplot(aes(x = author,y = SumSemiColons)) +
geom_bar(stat='identity',colour="white", fill = "darkseagreen4") +
labs(x = 'Author',
y = 'Semicolons',
title = 'Author and Total Number of Semicolons') +
coord_flip() +
theme_bw()
png("../figs/semicolons.png")
spooky %>%
group_by(author) %>%
summarise(SumSemiColons = sum(Nsemicolons,na.rm = TRUE)) %>%
ungroup() %>%
mutate(author = reorder(author,SumSemiColons)) %>%
ggplot(aes(x = author,y = SumSemiColons)) +
geom_bar(stat='identity',colour="white", fill = "darkseagreen4") +
labs(x = 'Author',
y = 'Semicolons',
title = 'Author and Total Number of Semicolons') +
coord_flip() +
theme_bw()
dev.off()
packages.used <- c("ggplot2", "dplyr", "tidytext", "wordcloud", "stringr", "ggridges", "tidyr", "RColorBrewer", "psych")
# check packages that need to be installed.
packages.needed <- setdiff(packages.used, intersect(installed.packages()[,1], packages.used))
# install additional packages
if(length(packages.needed) > 0) {
install.packages(packages.needed, dependencies = TRUE, repos = 'http://cran.us.r-project.org')
}
library(ggplot2)
library(dplyr)
library(tidytext)
library(wordcloud)
library(stringr)
library(ggridges)
library(tidyr)
library(RColorBrewer)
library(psych)
source("../libs/multiplot.R")
spooky <- read.csv('../data/spooky.csv', as.is = TRUE)
head(spooky)
summary(spooky)
spooky$text[1]
spooky$text[19579]
spooky$text[7500]
sum(is.na(spooky))
spooky$author <- as.factor(spooky$author) #change author variable to a factor for future analysis
# How many entries are there?
row.spooky <- nrow(spooky) #19579
# How many entries does each author have?
EAP <- spooky %>%
count(author == "EAP") #7900
HPL <- spooky %>%
count(author == "HPL") #5635
MWS <- spooky %>%
count(author == "MWS") #6044
a <- c("EAP", "HPL", "MWS")
w <- c(7900, 5635, 6044)
df = data.frame(a, w)
png("/Users/Nicole/Documents/GitHub/spring2018-project1-nas2184/figs/Bar_words_authors.png")
ggplot(df, aes(a, w)) +
geom_col(aes(fill = a)) + xlab("Author") + ylab("Number of Words") +
scale_fill_manual( values = c("lightsteelblue3","lemonchiffon2","honeydew4"))
dev.off()
spooky$len <- str_length(spooky$text)
png("../figs/median_sentence.png")
spooky %>%
group_by(author) %>%
summarise(CountMedian = median(len,na.rm = TRUE)) %>%
ungroup() %>%
mutate(author = reorder(author,CountMedian)) %>%
ggplot(aes(x = author,y = CountMedian)) +
geom_bar(stat='identity',colour="white", fill = "lightgoldenrod3") +
labs(x = 'Author',
y = 'Sentence Length',
title = 'Author and Median Sentence Length') +
coord_flip() +
theme_bw()
dev.off()
png("../figs/wordlength.png")
spooky %>%
ggplot(aes(x = len, fill = author)) +
geom_histogram() +
scale_x_continuous(limits = c(15,100)) +
scale_fill_manual( values = c("lightsteelblue3","lemonchiffon2","honeydew4")) +
facet_wrap(~author) +
labs(x= 'Word Length',y = 'Count', title = paste("Distribution of", ' Word Length ')) +
theme_bw()
dev.off()
spooky_word <- unnest_tokens(spooky, word, text)
head(spooky_word)
head(stop_words)
tail(stop_words)
spooky_word <- anti_join(spooky_word, stop_words, by = "word")
head(spooky_word)
# Words is a list of words, and freqs their frequencies
words <- count(group_by(spooky_word, word))$word
freqs <- count(group_by(spooky_word, word))$n
head(sort(freqs, decreasing = TRUE))
head
pal <- brewer.pal(8, "Set2")
png("../figs/Wordcloud_all.png")
wordcloud(words, freqs, scale = c(5, .2), min.freq = 3, max.words = 50, random.order = FALSE, rot.per = .15, colors = pal)
dev.off()
# Make a table with one word per row and remove `stop words` (i.e. the common words)
spooky_word <- unnest_tokens(spooky, word, text)
spooky_word <- anti_join(spooky_word, stop_words, by = "word")
# MWS
mws_spooky <- spooky_word %>%
filter(author == "MWS")
mws.words1 <- count(group_by(mws_spooky, word))$word
mws.freqs1 <- count(group_by(mws_spooky, word))$n
png("../figs/Wordcloud_mws.png")
wordcloud(mws.words1, mws.freqs1, scale = c(5, .2), min.freq = 3, max.words = 50, random.order = FALSE, rot.per = .15, colors = pal)
dev.off()
# HPL
hpl_spooky <- spooky_word %>%
filter(author == "HPL")
hpl.words1 <- count(group_by(hpl_spooky, word))$word
hpl.freqs1 <- count(group_by(hpl_spooky, word))$n
png("../figs/Wordcloud_hpl.png")
wordcloud(hpl.words1, hpl.freqs1, scale = c(5, .2), min.freq = 3, max.words = 50, random.order = FALSE, rot.per = .15, colors = pal)
dev.off()
# EAP
eap_spooky <- spooky_word %>%
filter(author == "EAP")
eap.words1 <- count(group_by(eap_spooky, word))$word
eap.freqs1 <- count(group_by(eap_spooky, word))$n
png("../figs/Wordcloud_eap.png")
wordcloud(eap.words1, eap.freqs1, scale = c(5, .2), min.freq = 3, max.words = 50, random.order = FALSE, rot.per = .15, colors = pal)
dev.off()
# Counts number of times each author used each word.
author_words <- count(group_by(spooky_word, word, author))
# Counts number of times each word was used.
all_words <- rename(count(group_by(spooky_word, word)), all = n)
author_words <- left_join(author_words, all_words, by = "word")
author_words <- arrange(author_words, desc(all))
author_words <- ungroup(head(author_words, 81))
png("../figs/author_words.png")
ggplot(author_words) +
geom_col(aes(reorder(word, all, FUN = min), n, fill = author)) +
scale_fill_manual( values = c("lightsteelblue3","lemonchiffon2","honeydew4")) +
xlab(NULL) +
coord_flip() +
facet_wrap(~ author) +
theme(legend.position = "none")
dev.off()
# Subset data to MWS only and make bigrams
mws.bigrams <- spooky %>%
filter(author == "MWS") %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
mws.bigrams %>%
count(bigram, sort = TRUE)
# Split bigram into one word per column
mws.split <- mws.bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
# Filter bigrams by "not"
stop_not <- stop_words %>%
filter(word == "not")
stop_not <- anti_join(stop_words, stop_not, by ="word")
mws.filtered <- mws.split %>%
filter(word1 == "not")
# Remove stop_words except for not
mws.filtered$word <- mws.filtered$word2
mws <- anti_join(mws.filtered, stop_not, by = "word")
# mws.words is a list of words, and mws.freqs their frequencies
mws.words <- count(group_by(mws, word2))$word2
mws.freqs <- count(group_by(mws, word2))$n
png("../figs/Wordcloud_mws_not.png")
wordcloud(mws.words, mws.freqs, scale = c(5, .2), min.freq = 3, max.words = Inf, random.order = FALSE, rot.per = .15, colors = pal)
dev.off()
# Subset data to HPL only and make bigrams
hpl.bigrams <- spooky %>%
filter(author == "HPL") %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
hpl.bigrams %>%
count(bigram, sort = TRUE)
# Split bigram into one word per column
hpl.split <- hpl.bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
# Filter bigrams by "not"
hpl.filtered <- hpl.split %>%
filter(word1 == "not")
# Remove stop_words except for not
hpl.filtered$word <- hpl.filtered$word2
hpl <- anti_join(hpl.filtered, stop_not, by = "word")
# hpl.words is a list of words, and hpl.freqs their frequencies
hpl.words <- count(group_by(hpl, word2))$word2
hpl.freqs <- count(group_by(hpl, word2))$n
png("../figs/Wordcloud_hpl_not.png")
wordcloud(hpl.words, hpl.freqs, scale = c(5, .2), min.freq = 3, max.words = Inf, random.order = FALSE, rot.per = .15, colors = pal)
dev.off()
# Subset data to EAP only and make bigrams
eap.bigrams <- spooky %>%
filter(author == "EAP") %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
eap.bigrams %>%
count(bigram, sort = TRUE)
# Split bigram into one word per column
eap.split <- eap.bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
# Filter bigrams by "not"
eap.filtered <- eap.split %>%
filter(word1 == "not")
# Remove stop_words except for not
eap.filtered$word <- eap.filtered$word2
eap <- anti_join(eap.filtered, stop_not, by = "word")
# eap.words is a list of words, and eap.freqs their frequencies
eap.words <- count(group_by(eap, word2))$word2
eap.freqs <- count(group_by(eap, word2))$n
png("../figs/Wordcloud_eap_not.png")
wordcloud(eap.words, eap.freqs, scale = c(5, .2), max.words = Inf, random.order = FALSE, rot.per = .15, colors = pal)
dev.off
stop_no <- stop_words %>%
filter(word %in% c("neither", "never", "no", "nobody", "non", "none", "noone", "not", "nothing", "nowhere"))
stop_neg <- anti_join(stop_words, stop_no, by = "word")
spooky_neg <- spooky %>%
unnest_tokens(word, text) %>%
anti_join(stop_neg, by = "word")
author_neg <- count(group_by(spooky_neg, word, author))
all_words_neg <- rename(count(group_by(spooky_neg, word)), all = n)
author_neg <- left_join(author_neg, all_words_neg, by = "word")
author_neg <- arrange(author_neg, desc(all))
author_neg <- ungroup(head(author_neg, 100))
png("../figs/author_neg.png")
ggplot(author_neg) +
geom_col(aes(reorder(word, all, FUN = min), n, fill = author)) +
scale_fill_manual( values = c("lightsteelblue3","lemonchiffon2","honeydew4")) +
xlab(NULL) +
coord_flip() +
facet_wrap(~ author) +
theme(legend.position = "none")
dev.off()
createFE <- function(ds)
{
ds = ds %>%
mutate(Ncommas = str_count(ds$text, ",")) %>%
mutate(Nsemicolons = str_count(ds$text, ";")) %>%
mutate(Ncolons = str_count(ds$text, ":"))
return(ds)
}
spooky <- createFE(spooky)
png("../figs/commas.png")
spooky %>%
group_by(author) %>%
summarise(SumCommas = sum(Ncommas,na.rm = TRUE)) %>%
ungroup() %>%
mutate(author = reorder(author,SumCommas)) %>%
ggplot(aes(x = author,y = SumCommas)) +
geom_bar(stat='identity',colour="white", fill = "slategray2") +
labs(x = 'Author',
y = 'Commas',
title = 'Author and Total Number of Commas') +
coord_flip() +
theme_bw()
dev.off()
png("../figs/semicolons.png")
spooky %>%
group_by(author) %>%
summarise(SumSemiColons = sum(Nsemicolons,na.rm = TRUE)) %>%
ungroup() %>%
mutate(author = reorder(author,SumSemiColons)) %>%
ggplot(aes(x = author,y = SumSemiColons)) +
geom_bar(stat='identity',colour="white", fill = "darkseagreen4") +
labs(x = 'Author',
y = 'Semicolons',
title = 'Author and Total Number of Semicolons') +
coord_flip() +
theme_bw()
dev.off()
png("../figs/colons.png")
spooky %>%
group_by(author) %>%
summarise(SumColons = sum(Ncolons,na.rm = TRUE)) %>%
ungroup() %>%
mutate(author = reorder(author,SumColons)) %>%
ggplot(aes(x = author,y = SumColons)) +
geom_bar(stat='identity',colour="white", fill = "antiquewhite2") +
labs(x = 'Author',
y = 'Number of colons',
title = 'Author and Total Number of Colons') +
coord_flip() +
theme_bw()
dev.off()
frequency <- count(spooky_word, author, word)
tf_idf <- bind_tf_idf(frequency, word, author, n)
head(tf_idf)
tail(tf_idf)
tf_idf <- arrange(tf_idf, desc(tf_idf))
tf_idf <- mutate(tf_idf, word = factor(word, levels = rev(unique(word))))
# Grab the top twenty tf_idf scores in all the words for each author
tf_idf <- ungroup(top_n(group_by(tf_idf, author), 20, tf_idf))
png("../figs/tf_idf.png")
ggplot(tf_idf) +
geom_col(aes(word, tf_idf, fill = author)) +
scale_fill_manual( values = c("lightsteelblue3","lemonchiffon2","honeydew4")) +
labs(x = NULL, y = "tf-idf") +
theme(legend.position = "none") +
facet_wrap(~ author, ncol = 3, scales = "free") +
coord_flip() +
labs(y = "TF-IDF values")
dev.off()
spooky_tf <- spooky %>%
unnest_tokens(word, text) %>%
count(author, word, sort = TRUE) %>%
ungroup()
total_words <- spooky_tf %>%
group_by(author) %>%
summarize(total = sum(n))
spooky_tf <- left_join(spooky_tf, total_words, by = "author")
png("../figs/spooky_tf.png")
ggplot(spooky_tf, aes(n/total, fill = author)) +
scale_fill_manual( values = c("lightsteelblue3","lemonchiffon2","honeydew4")) +
geom_histogram(show.legend = FALSE) +
stat_bin(binwidth = 0.00025) +
xlim(NA, 0.0009) +
facet_wrap(~author, ncol = 3, scales = "free_y")
dev.off()
freq_by_rank <- spooky_tf %>%
group_by(author) %>%
mutate(rank = row_number(),
`term frequency` = n/total)
png("../figs/zipf.png")
freq_by_rank %>%
ggplot(aes(rank, `term frequency`, color = author)) +
geom_abline(intercept = -0.62, slope = -1.1, color = "gray50", linetype = 2) +
geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) +
scale_x_log10() +
scale_y_log10()
dev.off
# Keep words that have been classified within the NRC lexicon.
get_sentiments('nrc')
sentiments <- inner_join(spooky_word, get_sentiments('nrc'), by = "word")
count(sentiments, sentiment)
#Record frequency of each sentiment/emotion for each author
count(sentiments, author, sentiment)
png("../figs/sentiments.png")
ggplot(count(sentiments, sentiment)) +
geom_col(aes(sentiment, n, fill = sentiment)) +
scale_fill_manual( values = c("antiquewhite3", "honeydew4", "lavenderblush4", "lemonchiffon2",  "lightsteelblue3",  "lightgoldenrod3", "rosybrown3", "mistyrose3",  "slategray2", "peachpuff3"))
dev.off()
png("../figs/sentiments_author.png")
ggplot(count(sentiments, author, sentiment)) +
geom_col(aes(sentiment, n, fill = sentiment)) +
scale_fill_manual( values = c("antiquewhite3", "honeydew4", "lavenderblush4", "lemonchiffon2",  "lightsteelblue3",  "lightgoldenrod3", "rosybrown3", "mistyrose3",  "slategray2", "peachpuff3")) +
facet_wrap(~ author) +
coord_flip() +
theme(legend.position = "none")
dev.off()
nrc_neg <- filter(get_sentiments('nrc'), sentiment == "negative")
nrc_neg
negative <- inner_join(spooky_neg, nrc_neg, by = "word")
head(negative)
count(negative, word, sort = TRUE)
neg_words <- count(group_by(negative, word, author))
neg_words_all <- count(group_by(negative, word))
neg_words <- neg_words %>%
left_join(neg_words_all, by = "word") %>%
arrange(desc(n.y)) %>%
head(100) %>%
ungroup()
png("../figs/neg_words.png")
ggplot(neg_words) +
geom_col(aes(reorder(word, n.y, FUN = min), n.x, fill = author)) +
scale_fill_manual( values = c("lightsteelblue3","lemonchiffon2","honeydew4")) +
xlab(NULL) +
coord_flip() +
facet_wrap(~author) +
theme(legend.position = "none")
dev.off()
sentiments.out <- anti_join(spooky_word, get_sentiments('nrc'), by = "word")
frequency_sent <- count(sentiments.out, author, word)
tf_idf_sent <- bind_tf_idf(frequency_sent, word, author, n)
head(tf_idf_sent)
tail(tf_idf_sent)
tf_idf_sent <- arrange(tf_idf_sent, desc(tf_idf))
tf_idf_sent <- mutate(tf_idf_sent, word = factor(word, levels = rev(unique(word))))
tf_idf_sent <- ungroup(top_n(group_by(tf_idf, author), 20, tf_idf))
png("../figs/tf_idf_sent.png")
ggplot(tf_idf_sent) +
geom_col(aes(word, tf_idf, fill = author)) +
scale_fill_manual( values = c("lightsteelblue3","lemonchiffon2","honeydew4")) +
labs(x = NULL, y = "tf-idf-sentiments") +
theme(legend.position = "none") +
facet_wrap(~ author, ncol = 3, scales = "free") +
coord_flip() +
labs(y = "TF-IDF of Missing Sentiments")
dev.off
sentiment.afinn <- spooky_word %>%
inner_join(get_sentiments("afinn"), by = "word") %>%
group_by(index = author) %>%
summarise(sentiment = sum(score)) %>%
mutate(method = "AFINN")
sentiment.bing.nrc <- bind_rows(spooky_word %>%
inner_join(get_sentiments("bing")) %>%
mutate(method = "Bing et al."),
spooky_word %>%
inner_join(get_sentiments("nrc") %>%
filter(sentiment %in% c("positive", "negative"))) %>%
mutate(method = "NRC")) %>%
count(method, index = author, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
png("../figs/sentiment3.png")
bind_rows(sentiment.afinn, sentiment.bing.nrc) %>%
ggplot(aes(index, sentiment, fill = method)) +
scale_fill_manual( values = c("lightsteelblue3","lemonchiffon2","honeydew4")) +
geom_col(show.legend = FALSE) +
facet_wrap(~method, ncol =1, scales = "free_y")
dev.off()
spooky_bigrams <- spooky %>%
select(author, text) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
bigrams_separated <- spooky_bigrams %>%
separate(bigram, c("word1", "word2", sep = " "))
bigrams_filtered <- bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
bigram_counts <- bigrams_filtered %>%
count(word1, word2, sort = TRUE)
bigrams_united <- bigrams_filtered %>%
unite(bigram, word1, word2, sep = " ")
bigram_tf_idf <- bigrams_united %>%
count(author, bigram) %>%
bind_tf_idf(bigram, author, n) %>%
arrange(desc(tf_idf))
png("../figs/bigram_tf_idf.png")
bigram_tf_idf  %>%
arrange(desc(tf_idf)) %>%
mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %>%
group_by(author) %>%
top_n(20, tf_idf) %>%
ungroup() %>%
ggplot(aes(bigram, tf_idf, fill = author)) +
scale_fill_manual( values = c("lightsteelblue3","lemonchiffon2","honeydew4")) +
geom_col() +
labs(x = NULL, y = "TF-IDF values") +
theme(legend.position = "none") +
facet_wrap(~ author, ncol = 3, scales = "free") +
coord_flip()
dev.off()
